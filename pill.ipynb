{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicine Box detection algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers \n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.optimizers as optim\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.sparse import csr_matrix\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"Pill_Detection\"\n",
    "IMG  = (256, 256, 3)\n",
    "GRID = (8, 8)\n",
    "FAC = IMG[0] / GRID[0]\n",
    "\n",
    "DEF_NUM = 4\n",
    "DEF_KER = 3\n",
    "DEF_STR = 1\n",
    "MOMENT = 0.95\n",
    "KREG = 3e-4\n",
    "BREG = 3e-6\n",
    "ACTF = \"silu\"\n",
    "VRED = 0.7\n",
    "XFAC = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2V = lambda x: x.reshape(-1, 1)\n",
    "_2L = lambda x: [int(x)] if type(x) == type(int()) else [int(c) for c in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_class_indexes(classes, class_list=None):\n",
    "    if type(class_list) == type(None):\n",
    "        class_list = list(set(list(classes)))\n",
    "    else:\n",
    "         class_list = list(set(class_list + list(classes)))\n",
    "    datapoint_index = A2V(np.array([class_list.index(data) for data in classes]))\n",
    "    return class_list, datapoint_index\n",
    "\n",
    "def make_grid(xmin, ymin, xmax, ymax, image_indexes, imgset, class_indexes, factor=FAC):\n",
    "    base_shape = np.zeros(((len(imgset), ) +  GRID + (6,)))\n",
    "    centerx = xmin\n",
    "    centery = ymin\n",
    "    width = A2V((xmax - xmin) )\n",
    "    height = A2V((ymax - ymin) )\n",
    "    boxx = np.array(centerx / factor, dtype=\"uint8\") \n",
    "    boxy = np.array(centery / factor, dtype=\"uint8\") \n",
    "    \n",
    "    centerx = A2V((centerx % factor) / factor) \n",
    "    centery = A2V((centery % factor) / factor)\n",
    "    width = width / factor \n",
    "    height = height / factor \n",
    "    print(image_indexes.shape, boxx.shape, boxy.shape)\n",
    "\n",
    "    base_shape[image_indexes, boxx, boxy, :] = np.concatenate([class_indexes, np.ones((class_indexes.shape)), centerx, centery, width, height], axis=1)\n",
    "    return base_shape\n",
    "    \n",
    "\n",
    "def read_folder(PATH, annotation = \"_annotations.csv\", class_list = None):\n",
    "        base_path = os.getcwd()\n",
    "    # try:\n",
    "        os.chdir(PATH)\n",
    "        dataset = pd.read_csv(annotation).values\n",
    "        image_set = list(set(dataset[:, 0]))\n",
    "        image_indexes = np.array([image_set.index(data) for data in  dataset[:, 0]])\n",
    "        x_train = np.array([cv2.cvtColor(cv2.resize(cv2.imread(datapoint), IMG[:2], cv2.INTER_CUBIC), cv2.COLOR_RGB2BGR) for datapoint in image_set])\n",
    "        print(type(image_indexes[0]))\n",
    "\n",
    "        W, H = dataset[:, 1:3].T\n",
    "        xmin, ymin, xmax, ymax = dataset[:, -4:].T\n",
    "        xmin = xmin * (IMG[0] / W )\n",
    "        xmax = xmax * (IMG[0] / W )\n",
    "        ymin = ymin * (IMG[1] / H )\n",
    "        ymax = ymax * (IMG[1] / H )\n",
    "        class_list, class_indexes = find_class_indexes(dataset[:, 3], class_list)\n",
    "        y_train = make_grid(xmin, ymin, xmax, ymax, image_indexes, image_set, class_indexes, FAC)\n",
    "        os.chdir(base_path)\n",
    "        return x_train, y_train, class_list\n",
    "         \n",
    "    # except Exception as e:\n",
    "    #     os.chdir(base_path)\n",
    "    #     print(base_path)\n",
    "    #     error_message = traceback.print_exc()\n",
    "    #     print(error_message)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(PATH)\n",
    "\n",
    "xtrain, ytrain, class_list = read_folder(PATH + \"/\" + folders[2] )\n",
    "xvalid, yvalid, _ = read_folder(PATH + \"/\" + folders[0], class_list=class_list )\n",
    "x_test, y_test, _ = read_folder(PATH + \"/\" + folders[1], class_list=class_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_reader(ytr, factor = FAC):\n",
    "    sparse_matrix_list = [csr_matrix(ytr[:, :, c]).tocoo() for c in range(ytr.shape[-1])]\n",
    "\n",
    "    centerx = sparse_matrix_list[-4].row * factor + sparse_matrix_list[-4].data * factor\n",
    "    centery = sparse_matrix_list[-4].col * factor + sparse_matrix_list[-3].data * factor\n",
    "\n",
    "    width_by_2  = sparse_matrix_list[-2].data * factor\n",
    "    height_by_2 = sparse_matrix_list[-1].data * factor\n",
    "    \n",
    "    xmin_list = _2L(centerx)\n",
    "    ymin_list = _2L(centery )\n",
    "    xmax_list = _2L(centerx + width_by_2)\n",
    "    ymax_list = _2L(centery + height_by_2)\n",
    "    return _2L(sparse_matrix_list[-5].data), xmin_list, ymin_list, xmax_list, ymax_list, list(sparse_matrix_list[0].data)\n",
    "\n",
    "\n",
    "def plot_box(image, ytr, factor = FAC):\n",
    "    conf_list, xmin_list, ymin_list, xmax_list, ymax_list, _ = point_reader(ytr, factor)\n",
    "    for conf, xmin, ymin, xmax, ymax in zip(conf_list, xmin_list, ymin_list, xmax_list, ymax_list):\n",
    "        if float(conf) > 0.5:\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 1, 1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "def IoU(ypred, ytrue, factor = FAC):\n",
    "    xmin_pred, ymin_pred, xmax_pred, ymax_pred = point_reader(ypred, factor)\n",
    "    xmin_true, ymin_true, xmax_true, ymax_true = point_reader(ytrue, factor)\n",
    "\n",
    "    int_x_min = max(xmin_true, xmin_pred)\n",
    "    int_y_min = max(ymin_pred, ymin_true)\n",
    "    int_x_max = min(xmax_true, xmax_pred)\n",
    "    int_y_max = min(ymax_pred, ymax_true)\n",
    "\n",
    "    int_width  = int_x_max - int_x_min \n",
    "    int_height = int_y_max - int_y_min\n",
    "\n",
    "    int_area = int_width * int_height \n",
    "\n",
    "    pred_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n",
    "    true_area = (xmax_true - xmax_true) * (ymax_true - ymin_true)\n",
    "\n",
    "    uno_area = pred_area + true_area - int_area \n",
    "\n",
    "    return int_area / uno_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = random.randint(0, xtrain.shape[0])\n",
    "plot_box(xtrain[c], ytrain[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xtrain[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(input_tensor, reduction_ratio=32, kernel_reg=1e-4, drop_se=0.2):\n",
    "    channels = input_tensor.shape[-1]\n",
    "    x = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    x = layers.Reshape((1, 1, channels))(x)\n",
    "    x = layers.Dense(channels // reduction_ratio, activation='relu', use_bias=False, kernel_regularizer=l2(kernel_reg))(x)\n",
    "    x = layers.Dropout(drop_se)(x)\n",
    "    x = layers.Dense(channels, activation='sigmoid', use_bias=False, kernel_regularizer=l2(kernel_reg))(x)\n",
    "    output = layers.Multiply()([input_tensor, x])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvOp(x, resx, denx:list, filters:int, num:int = DEF_NUM, kernel:int = DEF_KER, \n",
    "           stride:int = DEF_STR, moment:float = MOMENT, activation:str=ACTF, \n",
    "           kernel_reg:float=KREG, bias_reg:float=BREG, var_red:float=VRED, xp_factor = XFAC):\n",
    "    MBilters = filters\n",
    "    xlist = denx\n",
    "\n",
    "    kernels = range(-(kernel // 2), num - kernel // 2) if num > 1 else range(1)\n",
    "\n",
    "    for c in kernels:\n",
    "        reduce = abs(c) * 2 if c != 0 else 1\n",
    "        rilters = int(MBilters / reduce)\n",
    "        xl = layers.Conv2D(rilters, kernel + 2*c, padding=\"same\", strides= stride,\n",
    "                           kernel_regularizer=l2(kernel_reg), \n",
    "                           bias_regularizer=l1(bias_reg))(x)\n",
    "        xl = layers.BatchNormalization(momentum=moment)(xl)\n",
    "        xlist.append(xl)\n",
    "    xl = layers.MaxPool2D(3, stride, padding=\"same\")(x)\n",
    "    xl = layers.BatchNormalization(momentum=moment)(xl)\n",
    "\n",
    "    xlist.append(xl)\n",
    "    x = layers.Concatenate()(xlist)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel, padding=\"same\", \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer=l1(bias_reg))(x)\n",
    "    x = se_block(x)\n",
    "    nesx = layers.BatchNormalization(momentum=moment)(x)\n",
    "    x = layers.Activation(activation)(nesx + resx)\n",
    "\n",
    "    denx.append(x)\n",
    "    return x, nesx, denx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(x, residual_connect, dense_connect, filters, num_delta_x, \n",
    "              kernel:int = DEF_KER, moment:float = MOMENT, activation:str=ACTF, \n",
    "              kernel_reg:float=KREG, bias_reg:float=BREG, var_red:float=VRED, xp_factor = XFAC):\n",
    "    \n",
    "    for c, dense in enumerate(dense_connect):\n",
    "        dense = layers.Conv2D(filters, 3, padding=\"same\", strides=2,\n",
    "                         kernel_regularizer = l2(kernel_reg), \n",
    "                         bias_regularizer = l1(bias_reg))(dense)\n",
    "        dense = layers.BatchNormalization(momentum=moment)(dense)\n",
    "        dense_connect[c] = layers.Activation(activation)(dense)\n",
    "    \n",
    "    if dense_connect != []:\n",
    "        denx = layers.Concatenate()(dense_connect)\n",
    "        denx = layers.Conv2D(filters, kernel, padding=\"same\",\n",
    "                            kernel_regularizer = l2(kernel_reg), \n",
    "                            bias_regularizer = l1(bias_reg))(denx)\n",
    "        denx = layers.BatchNormalization(momentum=moment)(denx)\n",
    "        denx = [denx]\n",
    "    else:\n",
    "        denx = []\n",
    "    \n",
    "    resx1 = layers.Conv2D(filters, 3, strides=2, padding=\"same\",\n",
    "                         kernel_regularizer = l2(kernel_reg), \n",
    "                         bias_regularizer = l1(bias_reg))(residual_connect)\n",
    "    \n",
    "    resx2 = layers.MaxPool2D(2, 2)(residual_connect)\n",
    "    resx2 = layers.Conv2D(filters, 1,\n",
    "                         kernel_regularizer = l2(kernel_reg), \n",
    "                         bias_regularizer = l1(bias_reg))(resx2)\n",
    "    \n",
    "    resx = resx1 + resx2\n",
    "    \n",
    "    for c, num in enumerate(num_delta_x):\n",
    "        stride = 1 if c!=0 else 2\n",
    "        x, resx, denx = ConvOp(x, resx, denx, filters, num, kernel, stride, moment, \n",
    "                               activation, kernel_reg, bias_reg)\n",
    "    \n",
    "    denx = layers.Concatenate()(denx)\n",
    "    denx = layers.Conv2D(filters, kernel, padding=\"same\",\n",
    "                         kernel_regularizer = l2(kernel_reg), \n",
    "                         bias_regularizer = l1(bias_reg))(denx)\n",
    "    denx = layers.BatchNormalization(momentum=moment)(denx)\n",
    "    denx = layers.Activation(activation)(denx)\n",
    "\n",
    "    dense_connect.append(denx)\n",
    "\n",
    "    return x, resx, dense_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(seq_length, depth):\n",
    "    # Create a positional encoding matrix\n",
    "    position = tf.range(seq_length, dtype=tf.float32)[:, tf.newaxis]\n",
    "    div_term = tf.exp(tf.range(0, depth, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / depth))\n",
    "    \n",
    "    # Calculate sine and cosine for even and odd indices\n",
    "    pos_enc_even = tf.sin(position * div_term)\n",
    "    pos_enc_odd = tf.cos(position * div_term)\n",
    "    \n",
    "    # Concatenate the even and odd positional encodings\n",
    "    pos_enc = tf.concat([pos_enc_even, pos_enc_odd], axis=-1)\n",
    "    \n",
    "    return pos_enc\n",
    "\n",
    "def transformer_block(x, num_heads, ff_dim, dropout_rate=0.1):\n",
    "    # Multi-Head Self-Attention\n",
    "    attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=x.shape[-1])(x, x)\n",
    "    attention_output = layers.Dropout(dropout_rate)(attention_output)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + attention_output)  # Residual connection\n",
    "\n",
    "    # Feed Forward Network\n",
    "    ff_output = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff_output = layers.Dropout(dropout_rate)(ff_output)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff_output)  # Residual connection\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape = IMG, num_num = [ [4], [3], [2], [1]], num_trans_block:int=3, filters=64, classes = len(class_list), \n",
    "         kernel:int = DEF_KER, moment:float = MOMENT, activation:str=ACTF, kernel_reg:float=KREG, \n",
    "         bias_reg:float=BREG, var_red:float=VRED, xp_factor = XFAC, gf=2):\n",
    "    inp = layers.Input(input_shape)\n",
    "    x = layers.Conv2D(filters, 7, padding=\"same\", strides=2, \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(inp) # 256\n",
    "    x = layers.Activation(activation)(x)\n",
    "    resx = layers.Conv2D(filters, 3, padding=\"same\", strides=1, \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(x) # 256\n",
    "    x = layers.Activation(activation)(resx)\n",
    "\n",
    "    dense_connect = []\n",
    "    for num in num_num:\n",
    "        x, resx, dense_connect = ConvBlock(x, resx, dense_connect, filters, num, kernel, moment, \n",
    "                                           activation, kernel_reg, bias_reg, var_red, xp_factor)\n",
    "        filters = filters * gf\n",
    "        \n",
    "    x = layers.Conv2D(filters, 1, padding=\"same\", \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(x)\n",
    "    x = layers.BatchNormalization(momentum = moment)(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "        \n",
    "    # x = layers.Reshape((GRID[0] * GRID[1], filters))(x)  # Reshape to (batch_size, seq_length, channels)\n",
    "\n",
    "    # # Add positional encoding\n",
    "    # pos_enc = positional_encoding(GRID[0] * GRID[1], filters)\n",
    "    # x += pos_enc  # Add positional encoding to the input features\n",
    "\n",
    "    # # Transformer block\n",
    "    # for _ in range(num_trans_block):\n",
    "    #     x = transformer_block(x, num_heads=8, ff_dim=filters)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x =  layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(4096, activation=\"relu\", \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(x)\n",
    "    \n",
    "    cce = layers.Dropout(0.3)(x)\n",
    "    cce = layers.Dense(1024, activation=\"relu\", \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(cce)\n",
    "    cce = layers.Dropout(0.3)(cce)\n",
    "    cce = layers.Dense(GRID[0] * GRID[1] * classes, \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(cce)\n",
    "    cce = layers.Reshape((GRID[0], GRID[1], classes))(cce)\n",
    "    classification = layers.Softmax()(cce)\n",
    "    \n",
    "    con = layers.Dropout(0.5)(x)\n",
    "    con = layers.Dense(1024, activation=\"relu\", \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(con)\n",
    "    con = layers.Dropout(0.5)(con)\n",
    "    con = layers.Dense(GRID[0] * GRID[1], \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(con)\n",
    "    con = layers.Reshape((GRID[0], GRID[1], 1))(con)\n",
    "    confidence = layers.Activation(\"sigmoid\")(con)\n",
    "    \n",
    "    box = layers.Dropout(0.01)(x)\n",
    "    box = layers.Dense(4096, activation=\"relu\", \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(box)\n",
    "    box = layers.Dense(GRID[0] * GRID[1] * 4, \n",
    "                      kernel_regularizer=l2(kernel_reg), \n",
    "                      bias_regularizer = l1(bias_reg))(box)\n",
    "    boxes = layers.Reshape((GRID[0], GRID[1], 4))(box)\n",
    "    \n",
    "    out = layers.Concatenate()([classification, confidence, boxes])\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=out )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def binary_focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0, neg_weight=0.1):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)  # Avoid log(0)\n",
    "    pos_loss = -alpha * tf.pow(1 - y_pred, gamma) * y_true * tf.math.log(y_pred)\n",
    "    neg_loss = -(1 - alpha) * tf.pow(y_pred, gamma) * (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "    neg_loss *= neg_weight\n",
    "    focal_loss = pos_loss + neg_loss\n",
    "    return focal_loss\n",
    "\n",
    "def sparse_categorical_focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0, class_weights=None):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)  # Avoid log(0)\n",
    "    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
    "    y_true_one_hot = tf.squeeze(y_true_one_hot, axis=-2)  # Remove extra dimension if it exists\n",
    "    pred_prob = tf.reduce_sum(y_pred * y_true_one_hot, axis=-1)\n",
    "    \n",
    "    focal_loss = -alpha * tf.pow(1 - pred_prob, gamma) * tf.math.log(pred_prob)\n",
    "    \n",
    "    if class_weights is not None:\n",
    "        focal_loss *= class_weights\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred, beta=1.0):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    return tf.reduce_mean(diff, axis=-1)\n",
    "\n",
    "def point_reader_tensor(ytr, factor=FAC):\n",
    "    centerx, centery, width_by_2, height_by_2 = (\n",
    "        ytr[..., -4] * factor,\n",
    "        ytr[..., -3] * factor,\n",
    "        ytr[..., -2] * factor,\n",
    "        ytr[..., -1] * factor,\n",
    "    )\n",
    "    xmin, ymin = centerx , centery\n",
    "    xmax, ymax = centerx + width_by_2, centery + height_by_2\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def IoU_tensor(y_pred, y_true, factor=FAC, smooth=1e-6):\n",
    "    xmin_pred, ymin_pred, xmax_pred, ymax_pred = point_reader_tensor(y_pred, factor)\n",
    "    xmin_true, ymin_true, xmax_true, ymax_true = point_reader_tensor(y_true, factor)\n",
    "    int_xmin, int_ymin = tf.math.maximum(xmin_pred, xmin_true), tf.math.maximum(ymin_pred, ymin_true)\n",
    "    int_xmax, int_ymax = tf.math.minimum(xmax_pred, xmax_true), tf.math.minimum(ymax_pred, ymax_true)\n",
    "    int_area = tf.math.maximum(0.0, int_xmax - int_xmin) * tf.math.maximum(0.0, int_ymax - int_ymin)\n",
    "    pred_area = tf.math.maximum(0.0, (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred))\n",
    "    true_area = tf.math.maximum(0.0, (xmax_true - xmin_true) * (ymax_true - ymin_true))\n",
    "    union_area = pred_area + true_area - int_area\n",
    "    iou = (int_area) / (union_area + smooth)\n",
    "    return iou\n",
    "\n",
    "def robust_iou_loss(y_pred, y_true, factor=FAC, smooth=1e-6):\n",
    "    iou = IoU_tensor(y_pred, y_true, factor, smooth)\n",
    "    return 1 - iou  # Directly using IoU for loss\n",
    "\n",
    "def dice_loss_boxes(y_pred, y_true, factor=FAC, smooth=1e-6):\n",
    "    xmin_pred, ymin_pred, xmax_pred, ymax_pred = point_reader_tensor(y_pred, factor)\n",
    "    xmin_true, ymin_true, xmax_true, ymax_true = point_reader_tensor(y_true, factor)\n",
    "    int_xmin, int_ymin = tf.math.maximum(xmin_pred, xmin_true), tf.math.maximum(ymin_pred, ymin_true)\n",
    "    int_xmax, int_ymax = tf.math.minimum(xmax_pred, xmax_true), tf.math.minimum(ymax_pred, ymax_true)\n",
    "    int_area = tf.math.maximum(0.0, int_xmax - int_xmin) * tf.math.maximum(0.0, int_ymax - int_ymin)\n",
    "    pred_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n",
    "    true_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n",
    "    \n",
    "    dice_score = (2 * int_area + smooth) / (pred_area + true_area + smooth)\n",
    "    return 1 - dice_score  # Return the loss as 1 - Dice score\n",
    "\n",
    "def loss_function(y_true, y_pred, alpha=0.25, gamma=2.0, neg_weight=0.1, lambda_coord=5.0, \n",
    "                  lambda_noobj=0.5, lambda_class=1.0, lambda_iou=1.0, lambda_dice=1.0, \n",
    "                  factor=FAC, smooth=1e-6, beta=1.0, class_weights=None):\n",
    "    class_true = y_true[..., :-5]  # Class labels (one-hot encoded)\n",
    "    obj_true = y_true[..., -5:-4]  # Objectness score\n",
    "    bbox_true = y_true[..., -4:]  # Bounding box (x, y, w, h)\n",
    "\n",
    "    class_pred = y_pred[..., :-5]  # Predicted class scores\n",
    "    obj_pred = y_pred[..., -5:-4]  # Predicted objectness score\n",
    "    bbox_pred = y_pred[..., -4:]  # Predicted bounding box (x, y, w, h)\n",
    "\n",
    "    obj_mask = obj_true  # Only consider object cells for loss\n",
    "    noobj_mask = (1 - obj_true) * obj_pred  # No-object cells\n",
    "\n",
    "    focal_loss_obj = binary_focal_loss(obj_true, obj_pred * obj_true, alpha, gamma, neg_weight)\n",
    "    focal_loss_class = sparse_categorical_focal_loss(class_true, class_pred * obj_mask, alpha, gamma, class_weights)\n",
    "\n",
    "    loc_loss = smooth_l1_loss(bbox_true, bbox_pred * obj_mask, beta)\n",
    "    iou_loss = robust_iou_loss(bbox_pred * obj_mask, bbox_true, factor, smooth)\n",
    "    dice_loss = dice_loss_boxes(bbox_pred * obj_mask, bbox_true, factor, smooth)\n",
    "\n",
    "    class_loss = tf.reduce_mean(focal_loss_class) \n",
    "    focal_loss_obj = tf.reduce_mean(focal_loss_obj)\n",
    "    loc_loss = tf.reduce_sum(loc_loss)\n",
    "    iou_loss = tf.reduce_mean(iou_loss)\n",
    "    dice_loss = tf.reduce_mean(dice_loss)\n",
    "    no_obj_loss = tf.reduce_mean(noobj_mask)\n",
    "\n",
    "    total_loss =  focal_loss_obj + no_obj_loss + class_loss + loc_loss + iou_loss \n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true, y_pred, confidence_threshold=0.5):\n",
    "    \"\"\"IoU metric with confidence threshold based on union of true and predicted masks.\"\"\"\n",
    "    # Separate bounding box coordinates and confidence scores\n",
    "    bbox_true = y_true[..., -4:]\n",
    "    bbox_pred = y_pred[..., -4:]\n",
    "    obj_pred = y_true[..., -5:-4]\n",
    "\n",
    "    # Create confidence mask based on union of true and predicted objectness scores\n",
    "    confidence_mask = tf.cast((obj_pred >= confidence_threshold), tf.float32)\n",
    "\n",
    "    # Apply mask to bounding box predictions and ground truth\n",
    "    masked_bbox_true = bbox_true * confidence_mask\n",
    "    masked_bbox_pred = bbox_pred * confidence_mask\n",
    "\n",
    "    # Extract coordinates for the predicted and true boxes\n",
    "    xmin_pred, ymin_pred, xmax_pred, ymax_pred = point_reader_tensor(masked_bbox_pred)\n",
    "    xmin_true, ymin_true, xmax_true, ymax_true = point_reader_tensor(masked_bbox_true)\n",
    "\n",
    "    # Compute intersection\n",
    "    int_xmin = tf.math.maximum(xmin_pred, xmin_true)\n",
    "    int_ymin = tf.math.maximum(ymin_pred, ymin_true)\n",
    "    int_xmax = tf.math.minimum(xmax_pred, xmax_true)\n",
    "    int_ymax = tf.math.minimum(ymax_pred, ymax_true)\n",
    "    int_area = tf.math.maximum(0.0, int_xmax - int_xmin) * tf.math.maximum(0.0, int_ymax - int_ymin)\n",
    "\n",
    "    # Compute union\n",
    "    pred_area = tf.math.maximum(0.0, (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred))\n",
    "    true_area = tf.math.maximum(0.0, (xmax_true - xmin_true) * (ymax_true - ymin_true))\n",
    "    union_area = pred_area + true_area - int_area\n",
    "\n",
    "    # IoU: intersection over union\n",
    "    iou = (int_area ) / (union_area + 1e-6)  # Add a small epsilon for numerical stability\n",
    "\n",
    "    # Return the mean IoU\n",
    "    return tf.reduce_mean(iou)\n",
    "\n",
    "\n",
    "def accuracy_metric(y_true, y_pred):\n",
    "    # Extract class labels and predictions\n",
    "    class_true = y_true[..., :-5]  # True class labels (one-hot encoded)\n",
    "    class_pred = y_pred[..., :-5]  # Predicted class probabilities\n",
    "\n",
    "    # Extract objectness score and create a mask\n",
    "    obj_true = y_true[..., -5:-4]  # Objectness score\n",
    "    normal_mask = tf.cast(obj_true >= 0.5, tf.float32)  # Mask for object cells\n",
    "\n",
    "    # Predicted and true class indices\n",
    "    pred_class_indices = tf.argmax(class_pred, axis=-1)  # Predicted class index\n",
    "    true_class_indices = tf.argmax(class_true, axis=-1)  # True class index\n",
    "\n",
    "    # Compute matches\n",
    "    matches = tf.cast(tf.equal(pred_class_indices, true_class_indices), tf.float32)\n",
    "\n",
    "    # Apply mask to consider only object cells\n",
    "    matches *= normal_mask[..., 0]\n",
    "\n",
    "    # Compute accuracy\n",
    "    total_objects = tf.reduce_sum(normal_mask[..., 0]) + 1e-7  # Avoid division by zero\n",
    "    accuracy = tf.reduce_sum(matches) / total_objects\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def categorical_loss_metric(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    # Extract the class labels and class predictions\n",
    "    class_true = y_true[..., :-5]  # True class labels (sparse or one-hot encoded)\n",
    "    class_pred = y_pred[..., :-5]  # Predicted class probabilities\n",
    "    \n",
    "    # Mask to ensure we're only evaluating predictions where objectness > 0.5\n",
    "    obj_true = y_true[..., -5:-4]\n",
    "    normal_mask = tf.cast(obj_true >= 0.5, tf.float32)\n",
    "\n",
    "    # Compute Sparse Categorical Focal Loss (Classification Metric)\n",
    "    y_true_one_hot = tf.one_hot(tf.cast(tf.argmax(class_true, axis=-1), tf.int32), depth=tf.shape(class_pred)[-1])\n",
    "    pred_prob = tf.reduce_sum(class_pred * y_true_one_hot, axis=-1)\n",
    "    focal_loss = -alpha * tf.pow(1 - pred_prob, gamma) * tf.math.log(pred_prob + 1e-7)\n",
    "\n",
    "    # Apply mask\n",
    "    focal_loss *= normal_mask[..., 0]\n",
    "    \n",
    "    # Return mean loss as a metric\n",
    "    return tf.reduce_mean(focal_loss)\n",
    "\n",
    "def bce_metrics(y_true, y_pred, confidence_threshold=0.5):\n",
    "    \"\"\"Binary focal loss metric with confidence filter.\"\"\"\n",
    "    obj_true = y_true[..., -5:-4]\n",
    "    obj_pred = y_pred[..., -5:-4]\n",
    "\n",
    "    # Compute binary focal loss only for confident predictions\n",
    "    bce_loss = binary_focal_loss(obj_true, obj_pred)\n",
    "    return tf.reduce_mean(bce_loss)  # Average over confident predictions\n",
    "\n",
    "def smooth_l1_metric(y_true, y_pred, beta=1.0, confidence_threshold=0.5):\n",
    "    # Separate bounding box coordinates and confidence scores\n",
    "    bbox_true = y_true[..., -4:]\n",
    "    bbox_pred = y_pred[..., -4:]\n",
    "    obj_pred = y_pred[..., -5:-4]\n",
    "\n",
    "    # Apply confidence threshold\n",
    "    confidence_mask = tf.cast(obj_pred >= confidence_threshold, tf.float32)\n",
    "\n",
    "    # Apply mask to bounding box predictions and ground truth\n",
    "    masked_bbox_true = bbox_true * confidence_mask\n",
    "    masked_bbox_pred = bbox_pred * confidence_mask\n",
    "\n",
    "    # Compute Smooth L1 loss\n",
    "    diff = tf.abs(masked_bbox_true - masked_bbox_pred)\n",
    "    loss = tf.where(diff < beta, 0.5 * tf.square(diff) / beta, diff - 0.5 * beta)\n",
    "\n",
    "    # Return the mean as the metric value\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def confidence_accuracy(y_true, y_pred, threshold=0.5):\n",
    "    # Extract objectness (confidence) scores\n",
    "    obj_true = y_true[..., -5] # Ground truth object confidence (batch, grid, grid)\n",
    "    obj_pred = y_pred[..., -5]  # Predicted object confidence (batch, grid, grid)\n",
    "\n",
    "    # Create binary masks for predictions and ground truth based on the threshold\n",
    "    pred_mask = tf.cast(obj_pred >= threshold, tf.float32)  # Predicted confidence >= threshold\n",
    "    true_mask = tf.cast(obj_true >= threshold, tf.float32)  # True object confidence >= threshold\n",
    "\n",
    "    # Compute intersection and union of the masks\n",
    "    intersection = tf.reduce_sum(pred_mask * true_mask)  # Overlap between predicted and true boxes\n",
    "    union = tf.reduce_sum(pred_mask + true_mask) - intersection  # Union of predicted and true boxes\n",
    "\n",
    "    # Avoid division by zero\n",
    "    union = tf.maximum(union, 1e-6)\n",
    "\n",
    "    # Compute confidence accuracy\n",
    "    confidence_acc = intersection / union\n",
    "\n",
    "    return confidence_acc\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def confidence_accuracy2(y_true, y_pred, threshold=0.5):\n",
    "    ytrue = y_true[..., -5]\n",
    "    ypred = y_pred[..., -5]\n",
    "\n",
    "    # Convert predicted probabilities to binary predictions based on the threshold\n",
    "    y_pred_binary = tf.cast(ypred >= threshold, tf.float32)\n",
    "    \n",
    "    # Compute binary accuracy\n",
    "    correct_predictions = tf.equal(ytrue, y_pred_binary)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch, lr):\n",
    "    drop_rate = 0.75\n",
    "    epochs_drop = 10\n",
    "    if epoch % epochs_drop == 0 and epoch > 0:\n",
    "        return lr * drop_rate\n",
    "    return lr\n",
    "\n",
    "class RandomGridBoundingBoxPlotterCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_images, test_labels, class_names, factor=FAC, num_images=4):\n",
    "        self.test_images = test_images\n",
    "        self.test_labels = test_labels\n",
    "        self.class_names = class_names\n",
    "        self.factor = factor\n",
    "        self.num_images = num_images\n",
    "        plt.ion()  # Enable interactive plotting\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_indices = np.random.choice(len(self.test_images), self.num_images, replace=False)\n",
    "        predictions = self.model.predict(self.test_images[random_indices])\n",
    "\n",
    "        # Create a figure for the grid\n",
    "        fig, axes = plt.subplots(1, self.num_images, figsize=(15, 5))\n",
    "        fig.suptitle(f\"Epoch {epoch + 1} Predictions\", fontsize=16)\n",
    "\n",
    "        for idx, ax in enumerate(axes):\n",
    "            img = self.test_images[random_indices[idx]]\n",
    "            true_boxes = self.test_labels[random_indices[idx]]\n",
    "            pred_boxes = predictions[idx]\n",
    "\n",
    "            # Clear axes and plot image\n",
    "            ax.clear()\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # Plot true boxes (green) and predicted boxes (red)\n",
    "            self.plot_boxes(ax, true_boxes, pred_boxes)\n",
    "\n",
    "        # Refresh the plot\n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "        plt.close(fig)\n",
    "\n",
    "    def plot_boxes(self, ax, true_boxes, pred_boxes):\n",
    "        grid_size = 4  # Defined by the model output shape\n",
    "        for y in range(grid_size):\n",
    "            for x in range(grid_size):\n",
    "                # True boxes: Assume last dimension is (1 + 5) -> object confidence + bbox\n",
    "                true_box = true_boxes[y, x]\n",
    "                if true_box[-5] > 0.5:  # Confidence threshold\n",
    "                    xmin, ymin, xmax, ymax = point_reader_tensor(true_box[-4:], self.factor)\n",
    "                    ax.add_patch(\n",
    "                        plt.Rectangle(\n",
    "                            (y * self.factor + xmin, x * self.factor + ymin),\n",
    "                            xmax - xmin,  # Corrected width\n",
    "                            ymax - ymin,  # Corrected height\n",
    "                            linewidth=2,\n",
    "                            edgecolor=\"green\",\n",
    "                            facecolor=\"none\",\n",
    "                        )\n",
    "                    )\n",
    "                    ax.text(\n",
    "                        y * self.factor + xmin, \n",
    "                        x * self.factor + ymax,\n",
    "                        f\"True: {self.class_names[int(true_box[0])]}\",\n",
    "                        color=\"black\",\n",
    "                        fontsize=6,\n",
    "                        backgroundcolor=\"green\",\n",
    "                    )\n",
    "\n",
    "                # Predicted boxes: Assume last dimension is (8 + 5) -> class probabilities + bbox\n",
    "                pred_box = pred_boxes[y, x]\n",
    "                class_idx = tf.argmax(pred_box[:-5])\n",
    "                class_name = self.class_names[class_idx]\n",
    "                obj_confidence = pred_box[-5]\n",
    "                if obj_confidence > 0.5:  # Confidence threshold\n",
    "                    xmin, ymin, xmax, ymax = point_reader_tensor(pred_box[-4:], self.factor)\n",
    "                    ax.add_patch(\n",
    "                        plt.Rectangle(\n",
    "                            (y * self.factor + xmin, x * self.factor + ymin),\n",
    "                            xmax - xmin,  # Corrected width\n",
    "                            ymax - ymin,  # Corrected height\n",
    "                            linewidth=2,\n",
    "                            edgecolor=\"red\",\n",
    "                            facecolor=\"none\",\n",
    "                        )\n",
    "                    )\n",
    "                    ax.text(\n",
    "                        y * self.factor + xmin, \n",
    "                        x * self.factor + ymin - 5 ,\n",
    "                        f\"Pred: {class_name} ({obj_confidence:.2f})\",\n",
    "                        color=\"black\",\n",
    "                        fontsize=8,\n",
    "                        backgroundcolor=\"red\",\n",
    "                    )\n",
    "\n",
    "# Create the callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "random_plotter_callback = RandomGridBoundingBoxPlotterCallback(\n",
    "    test_images=xtrain,  # A batch of test images\n",
    "    test_labels=ytrain,  # Corresponding ground truth labels\n",
    "    class_names=class_list,\n",
    "    factor=FAC,\n",
    "    num_images=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetectionLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, num_classes, alpha=0.25, gamma=2.0, lambda_cls=1.0, lambda_bbox=1.0, lambda_obj=1.0):\n",
    "        super(ObjectDetectionLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.alpha = alpha  # Focal loss alpha\n",
    "        self.gamma = gamma  # Focal loss gamma\n",
    "        self.lambda_cls = lambda_cls  # Weight for classification loss\n",
    "        self.lambda_bbox = lambda_bbox  # Weight for bounding box regression loss\n",
    "        self.lambda_obj = lambda_obj  # Weight for objectness loss\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Parse predictions\n",
    "        bbox_preds = y_pred[..., -4:]  # Bounding box predictions\n",
    "        class_preds = y_pred[..., :-5]  # Class scores\n",
    "        objectness_preds = y_pred[..., -5:-4]  # Objectness score\n",
    "\n",
    "        # Parse ground truth\n",
    "        bbox_targets = y_true[..., -4:]  # Bounding box targets\n",
    "        class_targets = y_true[..., :-5]  # One-hot class targets\n",
    "        objectness_targets = y_true[..., -5:-4]  # Objectness targets\n",
    "\n",
    "        # Bounding box regression loss (CIoU loss)\n",
    "        bbox_loss = self.ciou_loss(bbox_targets, bbox_preds) * objectness_targets[..., 0]\n",
    "\n",
    "        # Classification loss (Focal Loss)\n",
    "        class_loss = self.focal_loss(class_targets, class_preds) * objectness_targets[..., 0]\n",
    "\n",
    "        # Objectness loss (Binary Cross-Entropy)\n",
    "        objectness_loss = tf.keras.losses.binary_crossentropy(objectness_targets, objectness_preds)\n",
    "\n",
    "        # Combine the losses\n",
    "        total_loss = (\n",
    "            self.lambda_bbox * tf.reduce_mean(bbox_loss) +\n",
    "            self.lambda_cls * tf.reduce_mean(class_loss) +\n",
    "            self.lambda_obj * tf.reduce_mean(objectness_loss)\n",
    "        )\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "    def focal_loss(self, y_true, y_pred):\n",
    "        # Ensure predictions are within a valid range to avoid log(0)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "        y_true = tf.one_hot(tf.argmax(y_true, axis=-1), depth=self.num_classes)\n",
    "\n",
    "        # Compute focal loss\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        scaling_factor = tf.pow(1 - y_pred, self.gamma)\n",
    "        focal_loss = self.alpha * scaling_factor * cross_entropy\n",
    "        return tf.reduce_sum(focal_loss, axis=-1)\n",
    "\n",
    "    def ciou_loss(self, y_true, y_pred):\n",
    "        # Convert (x_min, y_min, width, height) to (x1, y1, x2, y2)\n",
    "        x1_true, y1_true, w_true, h_true = tf.split(y_true, 4, axis=-1)\n",
    "        x1_pred, y1_pred, w_pred, h_pred = tf.split(y_pred, 4, axis=-1)\n",
    "\n",
    "        x2_true = x1_true + w_true\n",
    "        y2_true = y1_true + h_true\n",
    "        x2_pred = x1_pred + w_pred\n",
    "        y2_pred = y1_pred + h_pred\n",
    "\n",
    "        # Ensure predictions are positive and non-zero\n",
    "        w_true = tf.maximum(w_true, 1e-6)\n",
    "        h_true = tf.maximum(h_true, 1e-6)\n",
    "        w_pred = tf.maximum(w_pred, 1e-6)\n",
    "        h_pred = tf.maximum(h_pred, 1e-6)\n",
    "\n",
    "        # Calculate intersection\n",
    "        xi1 = tf.maximum(x1_true, x1_pred)\n",
    "        yi1 = tf.maximum(y1_true, y1_pred)\n",
    "        xi2 = tf.minimum(x2_true, x2_pred)\n",
    "        yi2 = tf.minimum(y2_true, y2_pred)\n",
    "        intersection = tf.maximum(0.0, xi2 - xi1) * tf.maximum(0.0, yi2 - yi1)\n",
    "\n",
    "        # Calculate union\n",
    "        area_true = w_true * h_true\n",
    "        area_pred = w_pred * h_pred\n",
    "        union = area_true + area_pred - intersection\n",
    "        union = tf.maximum(union, 1e-6)  # Prevent division by zero\n",
    "\n",
    "        # IoU\n",
    "        iou = intersection / union\n",
    "\n",
    "        # Center distance\n",
    "        cx_true = x1_true + 0.5 * w_true\n",
    "        cy_true = y1_true + 0.5 * h_true\n",
    "        cx_pred = x1_pred + 0.5 * w_pred\n",
    "        cy_pred = y1_pred + 0.5 * h_pred\n",
    "        center_dist = tf.square(cx_true - cx_pred) + tf.square(cy_true - cy_pred)\n",
    "\n",
    "        # Diagonal of the smallest enclosing box\n",
    "        x_min_enclose = tf.minimum(x1_true, x1_pred)\n",
    "        y_min_enclose = tf.minimum(y1_true, y1_pred)\n",
    "        x_max_enclose = tf.maximum(x2_true, x2_pred)\n",
    "        y_max_enclose = tf.maximum(y2_true, y2_pred)\n",
    "        diagonal_enclose = tf.square(x_max_enclose - x_min_enclose) + tf.square(y_max_enclose - y_min_enclose)\n",
    "        diagonal_enclose = tf.maximum(diagonal_enclose, 1e-6)  # Prevent division by zero\n",
    "\n",
    "        # Aspect ratio penalty\n",
    "        aspect_ratio_true = w_true / h_true\n",
    "        aspect_ratio_pred = w_pred / h_pred\n",
    "        aspect_ratio_penalty = tf.square(tf.math.log(tf.maximum(aspect_ratio_true, 1e-6)) - \n",
    "                                        tf.math.log(tf.maximum(aspect_ratio_pred, 1e-6)))\n",
    "\n",
    "        # CIoU with penalty terms\n",
    "        ciou = iou - (center_dist / diagonal_enclose) - (0.5 * aspect_ratio_penalty)\n",
    "\n",
    "        # Avoid NaN by clipping CIoU\n",
    "        ciou = tf.clip_by_value(ciou, -1.0, 1.0)\n",
    "\n",
    "        # Regression loss (Harsh version using cubic penalty)\n",
    "        abs_diff = tf.abs(y_true - y_pred)  # Absolute difference\n",
    "        regression_loss = tf.reduce_mean(tf.pow(abs_diff, 3), axis=-1)   # Cubic penalty for larger deviations\n",
    "\n",
    "        # Assuming ciou is also a part of the overall loss, reduce it\n",
    "        ciou = tf.reduce_mean(ciou, axis=-1)\n",
    "\n",
    "\n",
    "        # Combine CIoU and regression loss\n",
    "        alpha = 0.5 # Weight for CIoU\n",
    "        beta = 0.5   # Weight for regression loss\n",
    "        total_bbox_loss = alpha * (1 - ciou) + beta * regression_loss\n",
    "\n",
    "        return total_bbox_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain / 255.0\n",
    "max(xtrain.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(ytrain[:, :, :, 1:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 5.8699 - bce_metrics: 0.0061 - confidence_accuracy: 0.7145 - confidence_accuracy2: 0.9947 - smooth_l1_metric: 0.0021 - iou_metric: 0.0062 - categorical_loss_metric: 4.9032e-06 - accuracy_metric: 1.0000"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer= optim.legacy.Adam(learning_rate= 1e-4),\n",
    "    loss=ObjectDetectionLoss(num_classes=len(class_list)),\n",
    "    metrics=[bce_metrics, confidence_accuracy, confidence_accuracy2, smooth_l1_metric, iou_metric, categorical_loss_metric, accuracy_metric]\n",
    ")\n",
    "model.fit(xtrain, ytrain, epochs=250, verbose=1, validation_split=0.2, \n",
    "          callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(x_test[0:1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:, :, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:1, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box(x_test[0], results.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textreco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
